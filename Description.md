# INTRODUCTION
An significant part of a person's body is their face, which is particularly useful for interpreting
their behaviour and emotional condition. Without realising it, we categorise emotions
frequently. Without uttering a word, the human face is capable of expressing a wide range of
emotions. And unlike certain nonverbal communication techniques, these expressions can
recognized by all types of individuals and are universal. The most significant use of emotion
detection is in facial expression. The topic of emotion recognition is now the subject of much
research. Techniques for detecting mood using facial images yield results quickly and
effectively. Since the period of Aristotle, the ability to recognise emotional state in facial
expression has been a fascinating topic. After 1960, when a catalogue of universal emotions was
created and many systems were suggested, this idea gained greater traction. Our expectations
have increased since the advent of contemporary technology, which has no bounds.
People from all cultures around the globe all use the same facial expressions and body languages 
for joy, sorrow, anger, surprised, anxiety, and contempt. People who watch you can tell how 
you're feeling by the way your muscles move. In addition to many other primates and certain 
other animal species, they are the way by which societal information can be shared between 
humans. Humans may express themselves facially voluntarily or unintentionally. People often
produce involuntary expressions when they are unwell, injured, or uncomfortable. In social 
interaction, facial expressions of emotions play a significant role in understanding others' 
motives. Researcher took notice of that as well since about the capacity to recognise facial 
expressions aids in human-computer interaction, helps advertisers create effective
advertisements, and improves human communication process by modifying emotional 
intelligence (EQ) in people. On a daily basis, people can usually identify emotions by the 
distinctive qualities they present as part of a facial expression. For instance, a smiles or its 
upward movement of the lips' corner are certainly signs which indicate satisfaction. Similar to 
how one emotion can be distinguished from another by additional deformations unique to that
emotion. The questions revolves around the presentation and classification of either dynamic or 
static properties so all the formations and deformations of face pigments are addressed in
research on the automated identification of facial expressions. One of the primary 
informational streams in interpersonal interaction is facial expressions. Because of the
applications across perceptual and cognitive sciences, it is only natural that face emotion
research which had grabbed a lot of attention during the past decade..
With the fast advancement of Artificial Intelligent (AI) capabilities, interest in automated Facial
Emotion Recognition (FER) has indeed been rising recently.

## PROBLEM STATEMENT
In the evolving landscape of human-computer interaction, understanding and 
responding to human emotions play a crucial role in creating more intuitive and empathetic 
systems. Emotion detection technology aims to enhance user experiences by enabling machines 
to recognize and respond to the emotional states of users. However, there are several challenges 
that need to be addressed to achieve accurate and reliable emotion detection.
This field of face recognition deals with tactics and approaches for reading facial expressions
for emotions. The identification of emotions has become simpler because to several technical
advancements in the area of artificial intelligency and machine learnings. Expressions are
anticipated to become the next communication tool for computers. Automated facial analysis of 
emotions is becoming increasingly necessary. The majority of the studies in this field focuses 
on extracting emotional responses from movies or audio data. The majority of these studies work 
matches and recognises faces, however deep convolutional neural networks havenot been 
utilised to extract emotions from photos. 
Facial Emotion Recognition is a field of study that seeks to extract an emotion from a person's
facial expression. According to the polls, improvements in emotion detection have simplified
complicated systems. There are several uses for FER, which will be covered later. The difficult
problem of emotion recognition arises from the fact that emotions might differ based on the
situation, one's appearance, culture, and facial expression, which produces confusing data.
Understanding facial expression recognition is greatly aided by a survey on the subject.
Approach can be said as a machine learning that uses data models created specifically to do a
certain task. In the fields of image identification, classification, selection, pattern matching, etc.,
deep learning in neural network models has many applications. For selecting features,
picture recognition, and other deep learning applications, multi - modal deep learning is
utilised.
## SOFTWARE REQUIREMENT
Because the program is being created in Python, we used Anaconda for Python 3.6.5 and Spyder. 
Anaconda is an open source version of the Python and R programming languages to be used in 
projects related to data science and machine learnings with the aim of facilitating package 
management and installation . Package versioning is managed by a mechanism called Conda.
The Anaconda package, which provides over than 240+ well-liked data science applications
suitable to Microsoft windows, Linux, and Apple MacOS, is used by more than 60 lakhs
individuals. Spyder is a Python application framework that is open source and cross-platform
for use in the sciences.
SciPy, Matplotlib, Matplotlib, and IPython are all included in Spyder along with additional
open source software. It is provided under the MIT licence. Spyder, which can be extended by
plugins and provides interactive tools for data analysis, includes the Python-specific code quality 
assurance and introspection tools Pyflakes, Pylint, and Rope. With Anaconda, it is crossplatform compatible and usable on a variety of operating systems, including MacPortson the
Mac, WinPython and Python (x,y) on Windows, Debian, Fedora, Gentoo Linux, openSUSE, 
and Ubuntu
The features are:
o compatibility for a number of Python console, especially IPython;
o an editors featuring simple syntax and introspection for writing code;
o a GUI for updating variables. Two plugin which are easily accessible are Pylint's static code
analysis & Code Profiling.
o Conda Package Manager is used.
 Interfaces in hardware
1. Processor: Intel CORE i5 CPU with a minimum speed of 2.9 GHz.
2. RAM: 4 GB or more.
3. Hard drive: 500 GB minimum
 Interfaces in software
1. Google docs
2. Database Storage : Google sheet
3. Operating System : Microsoft Windows10
 PLANNING :
The procedures we used to create this project are as follows:
1. A review of the problem statement.
2. compiling the required information
3. A feasibility assessment of the proposal.
4. Development of an extensive concept
5. Checking the periodicals for past works in this field that are comparable.
6. Selecting an approach for the algorithm's construction.
7. Analyzing the numerous advantages and disadvantages.
8. developing the concept
9. The installation of programs like ANACONDA.
10. Developing an algorithms.
11. An evaluation of the algorithms by a mentor
12. Programming in Python using the generated algorithms The iterative waterfall method was
used to build the system
## SAMPLE IMAGES
![2](https://github.com/RuchithaReddy28/Emotion-Detection-Mini-Project/assets/93427261/720357b1-32b2-4bf2-8741-b3b18f66b484)


![3](https://github.com/RuchithaReddy28/Emotion-Detection-Mini-Project/assets/93427261/b5f39f22-fc98-4ea1-8372-a694677756c1)
## DIFFERENT METHODS OF CLASSIFICATION
They currently serve a variety of purposes, and human contact with them is growing. Machines
must be given the ability to comprehend the surroundings, particularly human intentions, in 
order to enhance Human Computer Interaction (HCI) and making it much more realistic. 
Employing surveillance cameras and sensor, computers may record the status of their
surroundings. Deep Learning (DL) algorithms have excelled in capturing environmental
conditions in recent years. Since emotions provide information about a person's inner state,
emotion detection is essential for robots to function more effectively. A machine is capable of
identifying human emotions from a series of face photos using DL approaches .
Deep learning models have shown to be particularly helpful for classifying and recognizing
patterns. The characteristics are the most crucial components of any deep learning system. In
this work, we are going to examine the extraction and modification of features for algorithms
like CNN. Algorithms and feature extraction methods from several articles will be compared.
The human facial emotion data may be used as a highly useful example to investigate the nature, 
resilience, and performance of classification methods for various dataset types. Face detection 
methods are often applied to the picture or video frame well before collection of components for 
emotion detection. The following are generalizations of the emotion detection procedures:
1) Preprocessing of data sets
2) Face recognition
3) Extracting feature
4) Classifications
utilizing relevant qualities Throughout this work, we place particular attention on the features
extracting process and emotions recognition utilizing the features extracted.
There have already been a number of projects in this area, thus our objective will not simplybe to create 
a deep learning model with annotated photographs of stable facial emotions and The project's objective 
technically entails training a deep convolutional neural network. Later, this network may be included into 
software that can identify and categorize the seven primary human emotion—happiness, sadness, surprise,
anger, disgust, neutrality, and fear—while increasing its accuracy of given system in comparison to the
baseline accuracy of 14.29 percent. Additionally, the precision of our model's output for each class will 
be examined as part of our study. Future performance of the model is anticipated to include identification 
of wild emotions with more complicated variation in conditions than laboratory conditions images wild
emotions with more complicated variation in conditions than laboratory conditions images.

